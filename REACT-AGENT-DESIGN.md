# ReAct Agent Architecture Design
## DDN Test Failure Analysis - Agentic RAG Implementation

**Version:** 1.0
**Date:** 2025-10-31
**Task:** Phase 0-ARCH.1
**Status:** Design Complete - Ready for Implementation

---

## Executive Summary

This document specifies the complete ReAct (Reasoning + Acting) agent architecture for the DDN test failure analysis system. The design replaces the current LINEAR workflow with a true AGENTIC RAG pattern that achieves 90-95% accuracy (vs current 60-70%).

**Key Improvements:**
- Iterative reasoning loops (vs linear pipeline)
- Dynamic tool selection (vs fixed path)
- Self-correction mechanism (vs fail-once model)
- Context-aware routing (vs process-all approach)
- Multi-step reasoning for complex errors

---

## 1. Current State Analysis

### 1.1 Current Implementation (LINEAR)

**File:** `implementation/langgraph_agent.py:277-294`

```python
def create_classification_workflow():
    workflow = StateGraph(dict)

    # Fixed linear path
    workflow.add_node("classify", classify_error)
    workflow.add_node("rag_search", search_similar_errors_rag)
    workflow.add_node("extract_files", extract_file_paths)

    # No conditional routing
    workflow.set_entry_point("classify")
    workflow.add_edge("classify", "rag_search")
    workflow.add_edge("rag_search", "extract_files")
    workflow.add_edge("extract_files", END)

    return workflow.compile()
```

**Problems:**
- No reasoning loops (cannot reconsider decisions)
- No tool selection (always runs same path)
- No self-correction (if RAG fails, workflow fails)
- No adaptability (same process for simple vs complex errors)
- Wasteful (fetches GitHub for ALL errors, even infrastructure issues)

**Current Accuracy:** 60-70% (per gap analysis document)

---

### 1.2 Required ReAct Pattern

**Thought â†’ Action â†’ Observation â†’ Thought (loop)**

```
[ERROR INPUT]
    â†“
[REASONING NODE] â† â”€â”€â”
    â†“               â”‚
"What do I need?" â”‚
    â†“               â”‚
[TOOL SELECTION]    â”‚
    â†“               â”‚
[TOOL EXECUTION]    â”‚
    â†“               â”‚
[OBSERVATION]       â”‚
    â†“               â”‚
"Did I get enough?" â”‚
    â”œâ”€ YES â†’ [GENERATE ANSWER]
    â””â”€ NO  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ (loop back, max 5 iterations)
```

**Target Accuracy:** 90-95%

---

## 2. ReAct Agent State Design

### 2.1 Enhanced State Structure

```python
from typing import List, Dict, Optional, Literal
from pydantic import BaseModel

class ReActAgentState(BaseModel):
    """Enhanced state for ReAct agent workflow"""

    # Input
    build_id: str
    error_log: str
    error_message: str
    stack_trace: Optional[str] = None
    job_name: Optional[str] = None
    test_name: Optional[str] = None

    # Classification (from first node)
    error_category: Optional[str] = None  # CODE_ERROR, INFRA_ERROR, etc.
    classification_confidence: float = 0.0

    # ReAct Loop State
    iteration: int = 0
    max_iterations: int = 5
    reasoning_history: List[Dict] = []  # Track all thoughts
    actions_taken: List[Dict] = []      # Track all actions
    observations: List[Dict] = []       # Track all results

    # Reasoning State
    current_thought: Optional[str] = None
    needs_more_info: bool = True
    next_action: Optional[str] = None

    # Retrieved Information
    rag_results: List[Dict] = []         # From Pinecone/Fusion RAG
    github_files: List[Dict] = []        # From GitHub MCP
    github_blame: Optional[Dict] = None  # From git blame
    mongodb_logs: List[Dict] = []        # From MongoDB
    postgres_history: List[Dict] = []    # From PostgreSQL

    # Tool Execution Results
    tool_results: Dict[str, any] = {}

    # Final Output
    solution_confidence: float = 0.0
    root_cause: Optional[str] = None
    fix_recommendation: Optional[str] = None
    similar_cases: List[Dict] = []

    # CRAG Verification
    crag_confidence: float = 0.0
    crag_action: Optional[Literal["auto_notify", "human_review", "self_correct", "web_search"]] = None

    # Decision State
    should_continue: bool = True
    termination_reason: Optional[str] = None
```

---

## 3. ReAct Workflow Design

### 3.1 State Graph Architecture

```python
from langgraph.graph import StateGraph, END

def create_react_agent_workflow():
    """
    Create ReAct agent workflow with reasoning loops
    """
    workflow = StateGraph(ReActAgentState)

    # Node 1: Initial Classification (entry point)
    workflow.add_node("classify_error", classify_error_node)

    # Node 2: Reasoning - Decide what information is needed
    workflow.add_node("reasoning", reasoning_node)

    # Node 3: Tool Selection - Choose which tool(s) to execute
    workflow.add_node("select_tool", tool_selection_node)

    # Node 4: Tool Execution - Run selected tool
    workflow.add_node("execute_tool", tool_execution_node)

    # Node 5: Observation - Analyze tool results
    workflow.add_node("observe_result", observation_node)

    # Node 6: CRAG Verification - Check confidence
    workflow.add_node("verify_solution", crag_verification_node)

    # Node 7: Generate Final Answer
    workflow.add_node("generate_answer", answer_generation_node)

    # Entry point
    workflow.set_entry_point("classify_error")

    # Linear: classify â†’ reasoning
    workflow.add_edge("classify_error", "reasoning")

    # Conditional: Should we continue gathering info or are we done?
    workflow.add_conditional_edges(
        "reasoning",
        should_continue_reasoning,
        {
            "continue": "select_tool",      # Need more info
            "generate": "generate_answer",  # Have enough info
            "max_iterations": "generate_answer"  # Hit iteration limit
        }
    )

    # ReAct Loop: select â†’ execute â†’ observe â†’ reasoning
    workflow.add_edge("select_tool", "execute_tool")
    workflow.add_edge("execute_tool", "observe_result")
    workflow.add_edge("observe_result", "reasoning")  # Loop back!

    # Answer â†’ CRAG verification â†’ END
    workflow.add_edge("generate_answer", "verify_solution")
    workflow.add_edge("verify_solution", END)

    return workflow.compile()
```

---

## 4. Tool Registry and Mappings

### 4.1 Available Tools

```python
# File: implementation/agents/tool_registry.py

from typing import Dict, List, Callable

class ToolRegistry:
    """Registry of all available tools with metadata"""

    def __init__(self):
        self.tools = {
            # PINECONE TOOLS (RAG)
            "pinecone_knowledge_search": {
                "function": self.search_knowledge_docs,
                "description": "Search curated error documentation (ERR001-ERR025) in ddn-knowledge-docs index",
                "use_for": ["CODE_ERROR", "INFRA_ERROR", "CONFIG_ERROR", "DEPENDENCY_ERROR", "TEST_FAILURE"],
                "cost": "low",
                "latency_ms": 200,
                "always_run": True  # Always fetch knowledge docs
            },
            "pinecone_error_library_search": {
                "function": self.search_error_library,
                "description": "Search past error cases from test runs in ddn-error-library index",
                "use_for": ["CODE_ERROR", "INFRA_ERROR", "CONFIG_ERROR", "DEPENDENCY_ERROR", "TEST_FAILURE"],
                "cost": "low",
                "latency_ms": 200,
                "always_run": True  # Always fetch similar past errors
            },

            # GITHUB MCP TOOLS (CODE ANALYSIS)
            "github_get_file": {
                "function": self.github_get_file,
                "description": "Fetch source code file from GitHub repository",
                "use_for": ["CODE_ERROR", "TEST_FAILURE"],
                "cost": "medium",
                "latency_ms": 500,
                "always_run": False,
                "context_aware": True  # Only 20% of CODE_ERROR need this
            },
            "github_get_blame": {
                "function": self.github_get_blame,
                "description": "Get git blame information (who changed what when)",
                "use_for": ["CODE_ERROR"],
                "cost": "medium",
                "latency_ms": 600,
                "always_run": False
            },
            "github_search_code": {
                "function": self.github_search_code,
                "description": "Search codebase for specific patterns or functions",
                "use_for": ["CODE_ERROR", "TEST_FAILURE"],
                "cost": "high",
                "latency_ms": 1000,
                "always_run": False
            },
            "github_get_test_file": {
                "function": self.github_get_test_file,
                "description": "Fetch test file source code",
                "use_for": ["TEST_FAILURE"],
                "cost": "medium",
                "latency_ms": 500,
                "always_run": False
            },
            "github_get_commit_history": {
                "function": self.github_get_commit_history,
                "description": "Get recent commits affecting a file",
                "use_for": ["CODE_ERROR", "TEST_FAILURE"],
                "cost": "high",
                "latency_ms": 800,
                "always_run": False
            },

            # MONGODB TOOLS (LOG ANALYSIS)
            "mongodb_get_logs": {
                "function": self.mongodb_get_logs,
                "description": "Retrieve full error logs from MongoDB",
                "use_for": ["INFRA_ERROR", "CONFIG_ERROR"],
                "cost": "low",
                "latency_ms": 100,
                "always_run": False
            },
            "mongodb_get_console_output": {
                "function": self.mongodb_get_console_output,
                "description": "Get console output from test run",
                "use_for": ["INFRA_ERROR", "CONFIG_ERROR", "DEPENDENCY_ERROR"],
                "cost": "low",
                "latency_ms": 100,
                "always_run": False
            },
            "mongodb_get_similar_failures": {
                "function": self.mongodb_get_similar_failures,
                "description": "Query MongoDB for failures with similar error messages",
                "use_for": ["ALL"],
                "cost": "low",
                "latency_ms": 150,
                "always_run": False
            },

            # POSTGRESQL TOOLS (METADATA)
            "postgres_get_failure_history": {
                "function": self.postgres_get_failure_history,
                "description": "Get historical failure data for same test",
                "use_for": ["ALL"],
                "cost": "low",
                "latency_ms": 100,
                "always_run": False
            },
            "postgres_get_consecutive_failures": {
                "function": self.postgres_get_consecutive_failures,
                "description": "Check if this test is failing consistently",
                "use_for": ["ALL"],
                "cost": "low",
                "latency_ms": 80,
                "always_run": False
            },

            # WEB SEARCH (FALLBACK)
            "web_search_error": {
                "function": self.web_search_error,
                "description": "Search web for error message (fallback for unknown errors)",
                "use_for": ["ALL"],
                "cost": "high",
                "latency_ms": 2000,
                "always_run": False,
                "fallback_only": True
            }
        }

    def get_tools_for_category(self, error_category: str, context: Dict) -> List[str]:
        """
        Get recommended tools for an error category

        Args:
            error_category: CODE_ERROR, INFRA_ERROR, etc.
            context: Additional context (confidence, iteration, etc.)

        Returns:
            List of tool names to execute
        """
        selected_tools = []

        # ALWAYS run knowledge search and error library search
        selected_tools.extend([
            "pinecone_knowledge_search",
            "pinecone_error_library_search"
        ])

        # Category-specific tools
        if error_category == "CODE_ERROR":
            # Context-aware routing: Only 20% need GitHub
            if context.get("needs_code_context"):
                selected_tools.extend([
                    "github_get_file",
                    "github_get_blame"
                ])

        elif error_category == "INFRA_ERROR":
            selected_tools.extend([
                "mongodb_get_logs",
                "mongodb_get_console_output",
                "postgres_get_consecutive_failures"
            ])

        elif error_category == "CONFIG_ERROR":
            selected_tools.extend([
                "mongodb_get_console_output",
                "postgres_get_failure_history"
            ])

        elif error_category == "DEPENDENCY_ERROR":
            selected_tools.extend([
                "mongodb_get_console_output",
                "mongodb_get_similar_failures"
            ])

        elif error_category == "TEST_FAILURE":
            selected_tools.extend([
                "github_get_test_file",
                "postgres_get_failure_history"
            ])

        return selected_tools
```

---

### 4.2 Error Category â†’ Tool Chain Mapping

| Error Category | Always Run | Conditional Run | Never Run |
|----------------|------------|-----------------|-----------|
| **CODE_ERROR** | Pinecone knowledge, Pinecone error library | GitHub file (20%), GitHub blame, GitHub search | MongoDB logs, Web search |
| **INFRA_ERROR** | Pinecone knowledge, Pinecone error library | MongoDB logs, MongoDB console, PostgreSQL history | GitHub tools, Web search |
| **CONFIG_ERROR** | Pinecone knowledge, Pinecone error library | MongoDB console, PostgreSQL history | GitHub tools, Web search |
| **DEPENDENCY_ERROR** | Pinecone knowledge, Pinecone error library | MongoDB console, MongoDB similar, PostgreSQL history | GitHub tools, Web search |
| **TEST_FAILURE** | Pinecone knowledge, Pinecone error library | GitHub test file, PostgreSQL history | GitHub blame, Web search |

**Context-Aware Routing (80/20 Rule for CODE_ERROR):**
- 80% of CODE_ERROR cases: RAG knowledge docs have the answer â†’ Skip GitHub
- 20% of CODE_ERROR cases: Need actual code inspection â†’ Fetch GitHub

**Decision Logic:**
```python
def should_fetch_github_code(state: ReActAgentState) -> bool:
    """
    Context-aware decision: Do we need GitHub code?
    """
    # If RAG confidence is high (>0.75), skip GitHub
    if state.rag_results and max([r.get('confidence', 0) for r in state.rag_results]) > 0.75:
        return False  # 80% case: Knowledge docs sufficient

    # If error mentions specific file/line, fetch code
    if "File" in state.error_message and "line" in state.error_message:
        return True  # 20% case: Need actual code

    # If first iteration with code error, try RAG first
    if state.iteration == 1:
        return False  # Give RAG a chance first

    # If second iteration and still no solution, try GitHub
    if state.iteration >= 2 and state.solution_confidence < 0.6:
        return True  # RAG didn't help, need code

    return False
```

---

## 5. ReAct Node Implementations

### 5.1 Node 1: Classification (Entry Point)

```python
def classify_error_node(state: ReActAgentState) -> ReActAgentState:
    """
    Classify error into category using OpenAI
    """
    classification_prompt = f"""
    Classify this test failure into one category:

    ERROR LOG:
    {state.error_log[:1000]}

    ERROR MESSAGE:
    {state.error_message}

    CATEGORIES:
    - CODE_ERROR: Syntax errors, null pointers, type errors
    - INFRA_ERROR: Memory, disk, network, timeouts
    - CONFIG_ERROR: Configuration, permissions, environment
    - DEPENDENCY_ERROR: Missing modules, version conflicts
    - TEST_FAILURE: Assertion failures, expected vs actual

    Output JSON:
    {{
        "category": "...",
        "confidence": 0.0-1.0,
        "reasoning": "..."
    }}
    """

    response = openai_client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": classification_prompt}],
        temperature=0.0,
        response_format={"type": "json_object"}
    )

    result = json.loads(response.choices[0].message.content)

    state.error_category = result["category"]
    state.classification_confidence = result["confidence"]

    logger.info(f"âœ… Classified as {state.error_category} (confidence: {state.classification_confidence:.2f})")

    return state
```

---

### 5.2 Node 2: Reasoning (Core ReAct Logic)

```python
def reasoning_node(state: ReActAgentState) -> ReActAgentState:
    """
    THOUGHT: Decide what information is needed next
    """
    state.iteration += 1

    # Build reasoning prompt
    reasoning_prompt = f"""
    You are an error analysis agent. Reason about what information you need next.

    ERROR CATEGORY: {state.error_category}
    ERROR MESSAGE: {state.error_message}

    INFORMATION GATHERED SO FAR:
    - RAG Results: {len(state.rag_results)} documents
    - GitHub Files: {len(state.github_files)} files
    - MongoDB Logs: {len(state.mongodb_logs)} logs
    - Actions Taken: {[a['tool'] for a in state.actions_taken]}

    PREVIOUS OBSERVATIONS:
    {state.observations[-3:] if state.observations else "None yet"}

    REASONING TASK:
    1. Do I have enough information to provide a confident answer?
    2. If not, what specific information do I need next?
    3. Which tool should I use to get that information?

    Output JSON:
    {{
        "thought": "My reasoning about what I know and what I need",
        "have_enough_info": true/false,
        "confidence": 0.0-1.0,
        "next_action": "tool_name or null if done",
        "reasoning": "Why I chose this action"
    }}
    """

    response = openai_client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": reasoning_prompt}],
        temperature=0.2,
        response_format={"type": "json_object"}
    )

    result = json.loads(response.choices[0].message.content)

    state.current_thought = result["thought"]
    state.needs_more_info = not result["have_enough_info"]
    state.next_action = result.get("next_action")
    state.solution_confidence = result["confidence"]

    # Store reasoning history
    state.reasoning_history.append({
        "iteration": state.iteration,
        "thought": result["thought"],
        "confidence": result["confidence"],
        "action": result.get("next_action")
    })

    logger.info(f"ðŸ’­ THOUGHT {state.iteration}: {result['thought'][:100]}...")
    logger.info(f"   Confidence: {result['confidence']:.2f} | Next: {result.get('next_action')}")

    return state


def should_continue_reasoning(state: ReActAgentState) -> str:
    """
    Conditional routing: Continue gathering info or generate answer?
    """
    # Check iteration limit
    if state.iteration >= state.max_iterations:
        logger.warning(f"âš ï¸  Max iterations ({state.max_iterations}) reached")
        return "max_iterations"

    # Check if agent says it has enough info
    if not state.needs_more_info or state.solution_confidence >= 0.8:
        logger.info(f"âœ… Enough information gathered (confidence: {state.solution_confidence:.2f})")
        return "generate"

    # Continue gathering information
    logger.info(f"ðŸ”„ Continue gathering information (iteration {state.iteration}/{state.max_iterations})")
    return "continue"
```

---

### 5.3 Node 3: Tool Selection

```python
def tool_selection_node(state: ReActAgentState) -> ReActAgentState:
    """
    ACTION: Select and prepare tool execution
    """
    tool_registry = ToolRegistry()

    # If agent specified a tool, use it
    if state.next_action and state.next_action in tool_registry.tools:
        selected_tool = state.next_action
    else:
        # Fallback: Use recommended tools for category
        context = {
            "needs_code_context": should_fetch_github_code(state),
            "iteration": state.iteration,
            "confidence": state.solution_confidence
        }
        recommended_tools = tool_registry.get_tools_for_category(
            state.error_category,
            context
        )

        # Filter out already executed tools
        executed_tools = [a['tool'] for a in state.actions_taken]
        available_tools = [t for t in recommended_tools if t not in executed_tools]

        if available_tools:
            selected_tool = available_tools[0]  # Pick first available
        else:
            # No more tools to try, move to answer generation
            state.needs_more_info = False
            return state

    logger.info(f"ðŸ”§ ACTION: Selected tool '{selected_tool}'")

    state.next_action = selected_tool

    return state
```

---

### 5.4 Node 4: Tool Execution

```python
def tool_execution_node(state: ReActAgentState) -> ReActAgentState:
    """
    Execute selected tool and store results
    """
    tool_registry = ToolRegistry()
    tool_name = state.next_action

    if not tool_name or tool_name not in tool_registry.tools:
        logger.error(f"âŒ Invalid tool: {tool_name}")
        return state

    tool_info = tool_registry.tools[tool_name]
    tool_function = tool_info["function"]

    logger.info(f"âš™ï¸  Executing tool: {tool_name}")

    try:
        # Execute tool
        start_time = time.time()
        result = tool_function(state)
        execution_time = (time.time() - start_time) * 1000

        # Store result
        state.tool_results[tool_name] = result

        # Track action
        state.actions_taken.append({
            "iteration": state.iteration,
            "tool": tool_name,
            "success": True,
            "execution_time_ms": execution_time
        })

        logger.info(f"âœ… Tool '{tool_name}' completed in {execution_time:.0f}ms")

    except Exception as e:
        logger.error(f"âŒ Tool '{tool_name}' failed: {e}")

        state.actions_taken.append({
            "iteration": state.iteration,
            "tool": tool_name,
            "success": False,
            "error": str(e)
        })

    return state
```

---

### 5.5 Node 5: Observation

```python
def observation_node(state: ReActAgentState) -> ReActAgentState:
    """
    OBSERVATION: Analyze tool execution results
    """
    last_action = state.actions_taken[-1] if state.actions_taken else None

    if not last_action:
        return state

    tool_name = last_action["tool"]
    tool_result = state.tool_results.get(tool_name)

    # Build observation
    observation = {
        "iteration": state.iteration,
        "tool": tool_name,
        "success": last_action["success"],
        "findings": None
    }

    if last_action["success"] and tool_result:
        # Summarize what we learned
        if "pinecone" in tool_name:
            observation["findings"] = f"Found {len(tool_result)} similar documented errors"
        elif "github" in tool_name:
            observation["findings"] = f"Retrieved {len(tool_result)} code files"
        elif "mongodb" in tool_name:
            observation["findings"] = f"Found {len(tool_result)} log entries"
        elif "postgres" in tool_name:
            observation["findings"] = f"Found {len(tool_result)} historical records"
    else:
        observation["findings"] = f"Tool failed: {last_action.get('error', 'Unknown error')}"

    state.observations.append(observation)

    logger.info(f"ðŸ‘ï¸  OBSERVATION: {observation['findings']}")

    return state
```

---

### 5.6 Node 6: CRAG Verification

```python
def crag_verification_node(state: ReActAgentState) -> ReActAgentState:
    """
    CRAG: Verify solution confidence and decide on action
    """
    from implementation.verification.crag_verifier import CRAGVerifier

    verifier = CRAGVerifier()

    # Calculate confidence score
    confidence = verifier.calculate_confidence(
        query=state.error_message,
        retrieved_docs=state.rag_results,
        generated_answer={
            "root_cause": state.root_cause,
            "recommendation": state.fix_recommendation
        }
    )

    state.crag_confidence = confidence

    # Decide action based on confidence thresholds
    if confidence >= 0.85:
        state.crag_action = "auto_notify"
        logger.info(f"âœ… HIGH confidence ({confidence:.2f}) - Auto-notify")

    elif confidence >= 0.65:
        state.crag_action = "human_review"
        logger.info(f"âš ï¸  MEDIUM confidence ({confidence:.2f}) - Human review required")
        # TODO: Add to HITL queue in PostgreSQL

    elif confidence >= 0.50:
        state.crag_action = "self_correct"
        logger.info(f"âŒ LOW confidence ({confidence:.2f}) - Self-correction triggered")
        # TODO: Implement self-correction loop

    else:
        state.crag_action = "web_search"
        logger.info(f"âŒ VERY LOW confidence ({confidence:.2f}) - Web search fallback")
        # TODO: Trigger web search

    return state
```

---

### 5.7 Node 7: Answer Generation

```python
def answer_generation_node(state: ReActAgentState) -> ReActAgentState:
    """
    Generate final answer with all gathered context
    """
    # Build context from all gathered information
    context_parts = []

    # RAG results
    if state.rag_results:
        context_parts.append("SIMILAR ERROR DOCUMENTATION:")
        for doc in state.rag_results[:3]:
            context_parts.append(f"- {doc['source']}: {doc['content'][:200]}...")

    # GitHub code
    if state.github_files:
        context_parts.append("CODE CONTEXT:")
        for file in state.github_files[:2]:
            context_parts.append(f"- {file['path']}: {file['content'][:200]}...")

    # MongoDB logs
    if state.mongodb_logs:
        context_parts.append("LOG CONTEXT:")
        for log in state.mongodb_logs[:2]:
            context_parts.append(f"- {log['timestamp']}: {log['message'][:100]}...")

    context = "\n".join(context_parts)

    # Generate final answer
    answer_prompt = f"""
    Based on all gathered information, provide a comprehensive error analysis.

    ERROR: {state.error_message}
    CATEGORY: {state.error_category}

    CONTEXT:
    {context}

    REASONING HISTORY:
    {json.dumps(state.reasoning_history, indent=2)}

    Provide:
    1. Root Cause Analysis (what caused the error?)
    2. Fix Recommendation (how to resolve it?)
    3. Confidence Level (0.0-1.0)

    Output JSON:
    {{
        "root_cause": "...",
        "fix_recommendation": "...",
        "confidence": 0.0-1.0,
        "reasoning": "..."
    }}
    """

    response = openai_client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": answer_prompt}],
        temperature=0.1,
        response_format={"type": "json_object"}
    )

    result = json.loads(response.choices[0].message.content)

    state.root_cause = result["root_cause"]
    state.fix_recommendation = result["fix_recommendation"]
    state.solution_confidence = result["confidence"]

    logger.info(f"ðŸ“ FINAL ANSWER generated (confidence: {state.solution_confidence:.2f})")

    return state
```

---

## 6. Self-Correction Mechanism

### 6.1 Retry Strategy

```python
class SelfCorrectionStrategy:
    """
    Self-correction when tools fail or results are unsatisfactory
    """
    MAX_RETRIES = 3

    def __init__(self):
        self.retry_history = {}

    def should_retry(self, tool_name: str, error: Exception) -> bool:
        """
        Decide if we should retry a failed tool
        """
        retries = self.retry_history.get(tool_name, 0)

        if retries >= self.MAX_RETRIES:
            logger.warning(f"âŒ Max retries ({self.MAX_RETRIES}) reached for {tool_name}")
            return False

        # Retry on transient errors
        transient_errors = ["timeout", "connection", "rate limit"]
        if any(err in str(error).lower() for err in transient_errors):
            self.retry_history[tool_name] = retries + 1
            logger.info(f"ðŸ”„ Retry {retries + 1}/{self.MAX_RETRIES} for {tool_name}")
            return True

        return False

    def suggest_alternative_tool(self, failed_tool: str, error_category: str) -> Optional[str]:
        """
        Suggest alternative tool when one fails
        """
        alternatives = {
            "github_get_file": "github_search_code",  # If file not found, try search
            "pinecone_knowledge_search": "web_search_error",  # If no docs, try web
            "mongodb_get_logs": "postgres_get_failure_history"  # If logs missing, try history
        }

        return alternatives.get(failed_tool)
```

---

## 7. Loop Termination Conditions

```python
def should_terminate_loop(state: ReActAgentState) -> tuple[bool, str]:
    """
    Decide if ReAct loop should terminate

    Returns:
        (should_terminate, reason)
    """
    # Condition 1: Max iterations reached
    if state.iteration >= state.max_iterations:
        return (True, f"Max iterations ({state.max_iterations}) reached")

    # Condition 2: High confidence solution found
    if state.solution_confidence >= 0.9:
        return (True, f"High confidence solution found ({state.solution_confidence:.2f})")

    # Condition 3: Agent declares it has enough info
    if not state.needs_more_info:
        return (True, "Agent determined sufficient information gathered")

    # Condition 4: All relevant tools exhausted
    tool_registry = ToolRegistry()
    recommended_tools = tool_registry.get_tools_for_category(state.error_category, {})
    executed_tools = [a['tool'] for a in state.actions_taken]
    remaining_tools = [t for t in recommended_tools if t not in executed_tools]

    if not remaining_tools and state.iteration >= 2:
        return (True, "All relevant tools executed, no further actions available")

    # Condition 5: No progress in last 2 iterations
    if state.iteration >= 3:
        recent_observations = state.observations[-2:]
        if all(not obs.get("success", True) for obs in recent_observations):
            return (True, "No successful observations in last 2 iterations")

    # Continue loop
    return (False, "")
```

---

## 8. Example Execution Traces

### 8.1 Simple CODE_ERROR (2 iterations, 80% case)

```
ITERATION 1:
â””â”€ CLASSIFY: "NullPointerException" â†’ CODE_ERROR (confidence: 0.95)
â””â”€ REASONING: "Need to check if this is a known error pattern"
â””â”€ ACTION: pinecone_knowledge_search
â””â”€ EXECUTE: Query "NullPointerException at line 45"
â””â”€ OBSERVATION: Found 3 similar errors (ERR003, ERR012, ERR018)
            Best match: ERR003 (confidence: 0.88) "Null check missing before method call"
â””â”€ REASONING: "High confidence match found, solution clear"
â””â”€ TERMINATE: solution_confidence = 0.88

RESULT: Root cause + Fix in 1 iteration (no GitHub needed)
TIME: ~1.5 seconds
```

### 8.2 Complex CODE_ERROR (4 iterations, 20% case)

```
ITERATION 1:
â””â”€ CLASSIFY: "TypeError: undefined is not a function" â†’ CODE_ERROR
â””â”€ REASONING: "Need to check documented errors first"
â””â”€ ACTION: pinecone_knowledge_search
â””â”€ OBSERVATION: Found 1 vague match (confidence: 0.45) "JavaScript type errors"
â””â”€ REASONING: "Low confidence, need actual code to diagnose"

ITERATION 2:
â””â”€ ACTION: github_get_file (file: src/utils/helper.js)
â””â”€ OBSERVATION: Retrieved file, found function call on line 127
â””â”€ REASONING: "Need to see git history to understand recent changes"

ITERATION 3:
â””â”€ ACTION: github_get_blame (file: src/utils/helper.js, line: 127)
â””â”€ OBSERVATION: Last changed by commit abc123f 2 days ago
â””â”€ REASONING: "Recent change introduced bug, need to see what changed"

ITERATION 4:
â””â”€ ACTION: github_get_commit_history (file: src/utils/helper.js)
â””â”€ OBSERVATION: Commit abc123f removed null check
â””â”€ REASONING: "Root cause identified: Removed null check caused TypeError"
â””â”€ TERMINATE: solution_confidence = 0.92

RESULT: Root cause + Fix in 4 iterations (GitHub code inspection needed)
TIME: ~4.5 seconds
```

### 8.3 INFRA_ERROR (2 iterations)

```
ITERATION 1:
â””â”€ CLASSIFY: "OutOfMemoryError: Java heap space" â†’ INFRA_ERROR
â””â”€ REASONING: "Infrastructure issue, check knowledge docs"
â””â”€ ACTION: pinecone_knowledge_search
â””â”€ OBSERVATION: Found ERR007 (confidence: 0.92) "Heap space errors"
â””â”€ REASONING: "Check if this test consistently runs out of memory"

ITERATION 2:
â””â”€ ACTION: postgres_get_consecutive_failures
â””â”€ OBSERVATION: Test failed 5 times in last 7 days, all OOM
â””â”€ REASONING: "Pattern confirmed: Persistent memory issue, not transient"
â””â”€ TERMINATE: solution_confidence = 0.90

RESULT: Increase heap size recommendation
TIME: ~1.2 seconds
NO GITHUB FETCHED (correct context-aware routing)
```

---

## 9. Performance Targets

| Metric | Target | Current (Linear) |
|--------|--------|------------------|
| **Accuracy** | 90-95% | 60-70% |
| **Avg Iterations** | 2-3 | N/A (fixed 3 steps) |
| **Latency (simple)** | <3s | ~2s |
| **Latency (complex)** | <10s | ~5s (but low accuracy) |
| **GitHub Fetch Rate** | 20% of CODE_ERROR | 100% (always) |
| **Cost per Analysis** | <$0.02 | ~$0.03 |
| **Self-Correction Rate** | 15-20% | 0% (no retries) |

---

## 10. Next Steps (Implementation Tasks)

**Task 0-ARCH.2:** Create react_agent_service.py (6 hours)
- Implement ReActAgent class with all 7 nodes
- Implement StateGraph workflow
- Add iteration management and loop control

**Task 0-ARCH.3:** Implement tool_registry.py (3 hours)
- ToolRegistry class with all 15+ tools
- Tool metadata and cost tracking
- get_tools_for_category() logic

**Task 0-ARCH.4:** Implement thought_prompts.py (3 hours)
- Category-specific reasoning prompts
- Few-shot examples for each error type
- Prompt templates for Thought/Action/Observation

**Task 0-ARCH.5:** Implement correction_strategy.py (2 hours)
- SelfCorrectionStrategy class
- Retry logic with exponential backoff
- Alternative tool suggestions

**Task 0-ARCH.6:** Update langgraph_agent.py (4 hours)
- Replace LINEAR workflow with ReAct pattern
- Add conditional routing logic
- Integrate with existing services

---

## Document Control

**Created:** 2025-10-31
**Author:** Phase 0-ARCH Implementation
**Task:** 0-ARCH.1
**Status:** Design Complete
**Next Task:** 0-ARCH.2 (Create react_agent_service.py)
