services:
  # ============================================================================
  # DATABASE LAYER
  # ============================================================================

  # NOTE: MongoDB Atlas is used (cloud-hosted).
  # Services use the `MONGODB_URI` environment variable from `.env`
  # pointing to your Atlas connection string.
  # No local MongoDB container needed.

  # PostgreSQL - Langfuse observability platform
  langfuse-db:
    image: postgres:15
    container_name: langfuse-postgres
    ports:
      - "5433:5432"
    environment:
      - POSTGRES_USER=langfuse
      - POSTGRES_PASSWORD=langfuse123
      - POSTGRES_DB=langfuse
    volumes:
      - D:/rancher-storage/volumes/langfuse-db-data:/var/lib/postgresql/data
    networks:
      - ddn-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U langfuse"]
      interval: 10s
      timeout: 5s
      retries: 5

  # PostgreSQL - Primary application database
  postgres:
    image: postgres:15
    container_name: ddn-postgres
    ports:
      - "5434:5432"
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=ddn_ai_analysis
    volumes:
      - D:/rancher-storage/volumes/postgres-data:/var/lib/postgresql/data
    networks:
      - ddn-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ============================================================================
  # CACHING & MESSAGING
  # ============================================================================

  # Redis - Cache and message broker
  redis:
    image: redis:latest
    container_name: ddn-redis
    ports:
      - "6379:6379"
    volumes:
      - D:/rancher-storage/volumes/redis-data:/data
    networks:
      - ddn-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  # ============================================================================
  # MONITORING & OBSERVABILITY
  # ============================================================================

  # Langfuse - LLM observability platform
  langfuse-server:
    image: ghcr.io/langfuse/langfuse:2
    container_name: langfuse-server
    ports:
      - "3000:3000"
    environment:
      - DATABASE_URL=postgresql://langfuse:langfuse123@langfuse-db:5432/langfuse
      - NEXTAUTH_URL=http://localhost:3000
      - NEXTAUTH_SECRET=very-secret-key-change-this-in-production-12345678
      - SALT=salt-change-this-in-production-abcdefgh
      - TELEMETRY_ENABLED=false
      - HOSTNAME=0.0.0.0
    networks:
      - ddn-network
    depends_on:
      langfuse-db:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "wget -q --spider http://0.0.0.0:3000/api/public/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Flower - Celery monitoring dashboard
  flower:
    build:
      context: ./implementation
      dockerfile: Dockerfile
    container_name: ddn-flower
    ports:
      - "5555:5555"
    volumes:
      - ./implementation:/app  # Auto-reload on code changes
    environment:
      - REDIS_URL=redis://redis:6379/0
    networks:
      - ddn-network
    depends_on:
      - redis
    restart: unless-stopped
    command: celery -A tasks.celery_tasks flower --port=5555 --broker=redis://redis:6379/0

  # ============================================================================
  # WORKFLOW AUTOMATION
  # ============================================================================

  # n8n - Workflow automation (using SQLite for workflow storage)
  n8n:
    image: n8nio/n8n:latest
    container_name: ddn-n8n
    ports:
      - "5678:5678"
    environment:
      - N8N_BASIC_AUTH_ACTIVE=true
      - N8N_BASIC_AUTH_USER=admin
      - N8N_BASIC_AUTH_PASSWORD=password
      - WEBHOOK_URL=http://localhost:5678/
    volumes:
      - D:/rancher-storage/volumes/n8n-data:/home/node/.n8n
      - ./implementation/workflows:/workflows
    networks:
      - ddn-network
    restart: unless-stopped

  # ============================================================================
  # TASK WORKERS
  # ============================================================================

  # Celery Worker - Async task processing
  celery-worker:
    build:
      context: ./implementation
      dockerfile: Dockerfile
    container_name: ddn-celery-worker
    volumes:
      - ./implementation:/app  # Auto-reload on code changes
    environment:
      - REDIS_URL=redis://redis:6379/0
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - MONGODB_URI=${MONGODB_URI}
      - PINECONE_API_KEY=${PINECONE_API_KEY}
      - LANGFUSE_ENABLED=true
      - LANGFUSE_HOST=http://langfuse-server:3000
      - LANGFUSE_PUBLIC_KEY=${LANGFUSE_PUBLIC_KEY}
      - LANGFUSE_SECRET_KEY=${LANGFUSE_SECRET_KEY}
    networks:
      - ddn-network
    depends_on:
      - redis
    restart: unless-stopped
    command: celery -A tasks.celery_tasks worker --loglevel=info --concurrency=4 --pool=solo

  # ============================================================================
  # CORE AI SERVICES
  # ============================================================================

  # LangGraph Classification Service
  langgraph-service:
    build:
      context: ./implementation
      dockerfile: Dockerfile
    container_name: ddn-langgraph
    ports:
      - "5000:5000"
    volumes:
      - ./implementation:/app  # Auto-reload on code changes
    environment:
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - MONGODB_URI=${MONGODB_URI}
      - MONGODB_DB=ddn_tests
      - PINECONE_API_KEY=${PINECONE_API_KEY}
      - PINECONE_INDEX_NAME=test-failures
      - REDIS_URL=redis://redis:6379/0
      - LANGFUSE_ENABLED=true
      - LANGFUSE_HOST=http://langfuse-server:3000
      - LANGFUSE_PUBLIC_KEY=${LANGFUSE_PUBLIC_KEY}
      - LANGFUSE_SECRET_KEY=${LANGFUSE_SECRET_KEY}
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=ddn_ai_analysis
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
    networks:
      - ddn-network
    depends_on:
      redis:
        condition: service_healthy
      postgres:
        condition: service_healthy
    restart: unless-stopped
    command: python langgraph_agent.py

  # ============================================================================
  # MCP SERVERS (Model Context Protocol)
  # ============================================================================

  # MongoDB MCP Server
  mcp-mongodb:
    build:
      context: ./mcp-configs
      dockerfile: Dockerfile
    container_name: ddn-mcp-mongodb
    ports:
      - "5001:5001"
    environment:
      - MONGODB_URI=${MONGODB_URI}
      - MONGODB_DB=ddn_tests
    dns:
      - 8.8.8.8
      - 1.1.1.1
    networks:
      - ddn-network
    restart: unless-stopped
    command: python mcp_mongodb_server.py

  # GitHub MCP Server
  mcp-github:
    build:
      context: ./mcp-configs
      dockerfile: Dockerfile
    container_name: ddn-mcp-github
    ports:
      - "5002:5002"
    environment:
      - GITHUB_TOKEN=${GITHUB_TOKEN}
      - GITHUB_REPO=${GITHUB_REPO}
    networks:
      - ddn-network
    restart: unless-stopped
    command: python mcp_github_server.py

  # ============================================================================
  # API SERVICES
  # ============================================================================

  # Manual Trigger API
  manual-trigger-api:
    build:
      context: ./implementation
      dockerfile: Dockerfile
    container_name: ddn-manual-trigger
    ports:
      - "5004:5004"
    volumes:
      - ./implementation:/app  # Auto-reload on code changes
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=ddn_ai_analysis
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - N8N_WEBHOOK_URL=http://n8n:5678/webhook/ddn-test-failure
      # AI API Keys - REQUIRED for real analysis
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      # MongoDB for failure data
      - MONGODB_URI=${MONGODB_URI}
      - MONGODB_DB=ddn_tests
      # Pinecone for RAG
      - PINECONE_API_KEY=${PINECONE_API_KEY}
      - PINECONE_INDEX_NAME=${PINECONE_INDEX_NAME}
      # LangGraph service
      - LANGGRAPH_URL=http://ddn-langgraph:5000
      # Dashboard API for storing results
      - DASHBOARD_API_URL=http://ddn-dashboard-api:5006
    networks:
      - ddn-network
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    command: python manual_trigger_api.py

  # Dashboard Backend API
  dashboard-api:
    build:
      context: ./implementation
      dockerfile: Dockerfile
    container_name: ddn-dashboard-api
    ports:
      - "5006:5006"  # Dashboard API port
    volumes:
      - ./implementation:/app  # Auto-reload on code changes
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=ddn_ai_analysis
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - MONGODB_URI=${MONGODB_URI}
      - MONGODB_DB=ddn_tests
      - MANUAL_TRIGGER_API=http://manual-trigger-api:5004
      - GITHUB_TOKEN=${GITHUB_TOKEN}
      - GITHUB_REPO=${GITHUB_REPO}
      - GITHUB_REPO_OWNER=${GITHUB_REPO_OWNER:-Sushrut-01}
      - GITHUB_REPO_NAME=${GITHUB_REPO_NAME:-ddn-test-data}
      - PINECONE_API_KEY=${PINECONE_API_KEY}
      - PINECONE_INDEX_NAME=${PINECONE_INDEX_NAME}
      - PINECONE_HOST=${PINECONE_HOST}
      - PINECONE_KNOWLEDGE_INDEX=${PINECONE_KNOWLEDGE_INDEX}
      - PINECONE_FAILURES_INDEX=${PINECONE_FAILURES_INDEX}
      # OpenAI for AI Chatbot
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      # Jira Integration (DDN Project - Default)
      - JIRA_URL=${JIRA_URL}
      - JIRA_EMAIL=${JIRA_EMAIL}
      - JIRA_API_TOKEN=${JIRA_API_TOKEN}
      - JIRA_PROJECT_KEY=${JIRA_PROJECT_KEY}
      # Multi-Project Support - Guruttava
      - GURUTTAVA_GITHUB_REPO_OWNER=${GURUTTAVA_GITHUB_REPO_OWNER:-Guruttava-Org}
      - GURUTTAVA_GITHUB_REPO_NAME=${GURUTTAVA_GITHUB_REPO_NAME:-guruttava-automation}
      - GURUTTAVA_JIRA_PROJECT_KEY=${GURUTTAVA_JIRA_PROJECT_KEY:-GURU}
      - GURUTTAVA_JIRA_URL=${GURUTTAVA_JIRA_URL}
      - GURUTTAVA_JIRA_EMAIL=${GURUTTAVA_JIRA_EMAIL}
      - GURUTTAVA_JIRA_TOKEN=${GURUTTAVA_JIRA_TOKEN}
      - GURUTTAVA_MONGODB_PREFIX=guruttava_
      - GURUTTAVA_PINECONE_NAMESPACE=guruttava
      # JWT Authentication
      - JWT_SECRET_KEY=temp-development-key-please-change-in-production-123456789
    dns:
      - 8.8.8.8
      - 1.1.1.1
    networks:
      - ddn-network
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    command: python dashboard_api_full.py

  # ============================================================================
  # INTEGRATION SERVICES
  # ============================================================================

  # Jira Integration Service
  jira-service:
    build:
      context: ./implementation
      dockerfile: Dockerfile
    container_name: ddn-jira
    ports:
      - "5009:5009"
    volumes:
      - ./implementation:/app  # Auto-reload on code changes
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=ddn_ai_analysis
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - JIRA_URL=${JIRA_URL}
      - JIRA_EMAIL=${JIRA_EMAIL}
      - JIRA_API_TOKEN=${JIRA_API_TOKEN}
      - JIRA_PROJECT_KEY=${JIRA_PROJECT_KEY}
      - JIRA_SERVICE_PORT=5009
    networks:
      - ddn-network
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    command: python jira_integration_service.py

  # Slack Integration Service
  slack-service:
    build:
      context: ./implementation
      dockerfile: Dockerfile
    container_name: ddn-slack
    ports:
      - "5012:5012"
    volumes:
      - ./implementation:/app  # Auto-reload on code changes
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=ddn_ai_analysis
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - SLACK_BOT_TOKEN=${SLACK_BOT_TOKEN}
      - SLACK_SIGNING_SECRET=${SLACK_SIGNING_SECRET}
      - SLACK_DEFAULT_CHANNEL=${SLACK_DEFAULT_CHANNEL}
      - SLACK_SERVICE_PORT=5012
      - DASHBOARD_URL=http://localhost:3000
    networks:
      - ddn-network
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    command: python slack_integration_service.py

  # Self-Healing Service
  self-healing-service:
    build:
      context: ./implementation
      dockerfile: Dockerfile
    container_name: ddn-self-healing
    ports:
      - "5008:5008"
    volumes:
      - ./implementation:/app  # Auto-reload on code changes
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=ddn_ai_analysis
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - JENKINS_URL=${JENKINS_URL}
      - JENKINS_USER=${JENKINS_USER}
      - JENKINS_TOKEN=${JENKINS_TOKEN}
      - GITHUB_TOKEN=${GITHUB_TOKEN}
      - GITHUB_REPO=${GITHUB_REPO}
      - SELF_HEALING_SAFE_MODE=true
      - MIN_SUCCESS_RATE=0.8
      - MIN_PATTERN_OCCURRENCES=3
    networks:
      - ddn-network
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    command: python self_healing_service.py

  # Service Manager API
  service-manager:
    build:
      context: ./implementation
      dockerfile: Dockerfile
    container_name: ddn-service-manager
    ports:
      - "5007:5007"
    volumes:
      - ./implementation:/app  # Auto-reload on code changes
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=ddn_ai_analysis
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - MONGODB_URI=${MONGODB_URI}
      - MONGODB_DB=ddn_tests
      - SERVICE_MANAGER_PORT=5007
    networks:
      - ddn-network
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    command: python service_manager_api.py

  # Aging Service
  aging-service:
    build:
      context: ./implementation
      dockerfile: Dockerfile
    container_name: ddn-aging-service
    ports:
      - "5010:5010"
    volumes:
      - ./implementation:/app  # Auto-reload on code changes
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=ddn_ai_analysis
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - MONGODB_URI=${MONGODB_URI}
      - MONGODB_DB=ddn_tests
      - AGING_SERVICE_PORT=5010
      - CHECK_INTERVAL_HOURS=24
    networks:
      - ddn-network
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    command: python aging_service.py

  # Knowledge Management API
  knowledge-management-api:
    build:
      context: ./implementation
      dockerfile: Dockerfile
    container_name: ddn-knowledge-mgmt
    ports:
      - "5015:5015"
    volumes:
      - ./implementation:/app  # Auto-reload on code changes
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - PINECONE_API_KEY=${PINECONE_API_KEY}
      - PINECONE_INDEX_NAME=test-failures
      - KNOWLEDGE_API_PORT=5015
      - MONGODB_URI=${MONGODB_URI}
      - MONGODB_DB=ddn_tests
    networks:
      - ddn-network
    restart: unless-stopped
    command: python knowledge_management_api.py

  # Re-Ranking Service
  reranking-service:
    build:
      context: ./implementation
      dockerfile: Dockerfile
    container_name: ddn-reranking
    ports:
      - "5011:5011"
    volumes:
      - ./implementation:/app  # Auto-reload on code changes
    environment:
      - RERANKING_SERVICE_PORT=5011
      - RERANKING_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2
      - MONGODB_URI=${MONGODB_URI}
      - MONGODB_DB=ddn_tests
    networks:
      - ddn-network
    restart: unless-stopped
    command: python reranking_service.py

  # ============================================================================
  # AUTHENTICATION & NOTIFICATIONS
  # ============================================================================

  # Authentication Service (JWT + User Management)
  auth-service:
    build:
      context: ./implementation
      dockerfile: Dockerfile
    container_name: ddn-auth-service
    ports:
      - "5013:5013"
    volumes:
      - ./implementation:/app  # Auto-reload on code changes
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=ddn_ai_analysis
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
      - JWT_ALGORITHM=HS256
      - TOKEN_EXPIRE_MINUTES=60
      - REFRESH_TOKEN_EXPIRE_DAYS=7
      - SERVICE_PORT=5013
    networks:
      - ddn-network
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    command: python auth_service.py
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5013/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Notifications Service (Email + In-App)
  notifications-service:
    build:
      context: ./implementation
      dockerfile: Dockerfile
    container_name: ddn-notifications
    ports:
      - "5014:5014"
    volumes:
      - ./implementation:/app  # Auto-reload on code changes
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=ddn_ai_analysis
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - SERVICE_PORT=5014
      # SMTP Configuration
      - SMTP_HOST=${SMTP_HOST:-smtp.gmail.com}
      - SMTP_PORT=${SMTP_PORT:-587}
      - SMTP_USERNAME=${SMTP_USERNAME}
      - SMTP_PASSWORD=${SMTP_PASSWORD}
      - SMTP_FROM_ADDRESS=${SMTP_FROM_ADDRESS:-DDN AI <noreply@ddn-ai.com>}
      - SMTP_USE_TLS=true
      # Redis for async tasks
      - REDIS_URL=redis://redis:6379/0
    networks:
      - ddn-network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    command: python notifications_service.py
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5014/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Workflow Executions API (n8n-style execution viewer)
  workflow-executions:
    build:
      context: ./implementation
      dockerfile: Dockerfile
    container_name: ddn-workflow-executions
    ports:
      - "5016:5016"
    volumes:
      - ./implementation:/app  # Auto-reload on code changes
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=ddn_ai_analysis
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - SERVICE_PORT=5016
    networks:
      - ddn-network
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    command: python workflow_executions_api.py
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5016/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ============================================================================
  # FRONTEND
  # ============================================================================

  # Dashboard Frontend (React)
  dashboard-ui:
    build:
      context: ./implementation/dashboard-ui
      dockerfile: Dockerfile
      target: development  # Use development mode with Vite dev server
    container_name: ddn-dashboard-ui
    ports:
      - "5173:5173"
    volumes:
      # Mount source code for hot reload - changes reflect immediately
      - ./implementation/dashboard-ui/src:/app/src
      - ./implementation/dashboard-ui/public:/app/public
      - ./implementation/dashboard-ui/index.html:/app/index.html
    environment:
      - VITE_API_URL=http://localhost:5006
      - VITE_JIRA_API_URL=http://localhost:5009
      - VITE_SLACK_API_URL=http://localhost:5012
      - VITE_KNOWLEDGE_API_URL=http://localhost:5015
      - VITE_SERVICE_MANAGER_URL=http://localhost:5007
      - VITE_WORKFLOW_API_URL=http://localhost:5016
      - VITE_AUTH_API_URL=http://localhost:5013
      - VITE_TRIGGER_API_URL=http://localhost:5004
    networks:
      - ddn-network
    depends_on:
      - dashboard-api
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "wget -q --spider http://localhost:5173 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Dashboard Frontend (Development Mode) - Use with: docker compose up dashboard-ui-dev
  dashboard-ui-dev:
    build:
      context: ./implementation/dashboard-ui
      dockerfile: Dockerfile
      target: development  # Use development stage for hot reload
    container_name: ddn-dashboard-ui-dev
    ports:
      - "5173:5173"
    environment:
      - VITE_API_URL=http://dashboard-api:5006
      - VITE_JIRA_API_URL=http://jira-service:5009
      - VITE_SLACK_API_URL=http://slack-service:5012
      - VITE_KNOWLEDGE_API_URL=http://knowledge-management-api:5015
      - VITE_SERVICE_MANAGER_URL=http://service-manager:5007
      - VITE_WORKFLOW_API_URL=http://workflow-executions:5016
      - VITE_AUTH_API_URL=http://auth-service:5013
    volumes:
      - ./implementation/dashboard-ui/src:/app/src:ro  # Mount source for hot reload
    networks:
      - ddn-network
    depends_on:
      - dashboard-api
    restart: unless-stopped
    profiles:
      - dev  # Only start with: docker compose --profile dev up

  # ============================================================================
  # CI/CD
  # ============================================================================

  # Jenkins CI Server
  jenkins:
    image: jenkins/jenkins:lts
    container_name: ddn-jenkins
    ports:
      - "8081:8081"
      - "50000:50000"
    environment:
      - JENKINS_OPTS=--httpPort=8081
      - JAVA_OPTS=-Xmx2048m
    volumes:
      - D:/rancher-storage/volumes/jenkins-data:/var/jenkins_home
      - ./jenkins-jobs:/var/jenkins_home/jobs  # Pre-configured Jenkins jobs
    networks:
      - ddn-network
    # CRITICAL: Docker Chrome requires these settings (proven from web research)
    shm_size: 2gb  # Chrome crashes with default 64MB /dev/shm (Chromium bug)
    cap_add:
      - SYS_ADMIN  # Chrome requires this capability in Docker containers
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8081/login || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s

  # Appium Server for Mobile Testing (Guruttava Project)
  appium:
    image: appium/appium:latest
    container_name: guruttava-appium
    ports:
      - "4723:4723"
    volumes:
      - ./mobile-apps:/apps  # APK/IPA files for testing
      - ./test-results:/test-results  # Test output
    environment:
      - RELAXED_SECURITY=true
      - APPIUM_LOG_LEVEL=info
      - ANDROID_HOME=/opt/android
      # Set timezone
      - TZ=UTC
    networks:
      - ddn-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:4723/wd/hub/status || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    # Note: For real device testing, you'll need privileged mode
    # privileged: true

# ============================================================================
# NETWORKS
# ============================================================================
networks:
  ddn-network:
    driver: bridge

# ============================================================================
# VOLUMES (Using D: drive for Rancher Desktop)
# ============================================================================
# All volumes now use bind mounts to D:/rancher-storage/volumes/
# No named volumes needed - data persists on D: drive
