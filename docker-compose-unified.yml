services:
  # ============================================================================
  # DATABASE LAYER
  # ============================================================================

  # NOTE: MongoDB Atlas is used (cloud-hosted).
  # Services use the `MONGODB_URI` environment variable from `.env`
  # pointing to your Atlas connection string.
  # No local MongoDB container needed.

  # PostgreSQL - Langfuse observability platform
  langfuse-db:
    image: postgres:15
    container_name: langfuse-postgres
    ports:
      - "5433:5432"
    environment:
      - POSTGRES_USER=langfuse
      - POSTGRES_PASSWORD=langfuse123
      - POSTGRES_DB=langfuse
    volumes:
      - D:/rancher-storage/volumes/langfuse-db-data:/var/lib/postgresql/data
    networks:
      - ddn-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U langfuse"]
      interval: 10s
      timeout: 5s
      retries: 5

  # PostgreSQL - Primary application database
  postgres:
    image: postgres:15
    container_name: ddn-postgres
    ports:
      - "5434:5432"
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=ddn_ai_analysis
    volumes:
      - D:/rancher-storage/volumes/postgres-data:/var/lib/postgresql/data
    networks:
      - ddn-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ============================================================================
  # CACHING & MESSAGING
  # ============================================================================

  # Redis - Cache and message broker
  redis:
    image: redis:latest
    container_name: ddn-redis
    ports:
      - "6379:6379"
    volumes:
      - D:/rancher-storage/volumes/redis-data:/data
    networks:
      - ddn-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  # ============================================================================
  # MONITORING & OBSERVABILITY
  # ============================================================================

  # Langfuse - LLM observability platform
  langfuse-server:
    image: ghcr.io/langfuse/langfuse:2
    container_name: langfuse-server
    ports:
      - "3000:3000"
    environment:
      - DATABASE_URL=postgresql://langfuse:langfuse123@langfuse-db:5432/langfuse
      - NEXTAUTH_URL=http://localhost:3000
      - NEXTAUTH_SECRET=very-secret-key-change-this-in-production-12345678
      - SALT=salt-change-this-in-production-abcdefgh
      - TELEMETRY_ENABLED=false
      - HOSTNAME=0.0.0.0
    networks:
      - ddn-network
    depends_on:
      langfuse-db:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "wget -q --spider http://0.0.0.0:3000/api/public/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Flower - Celery monitoring dashboard
  flower:
    build:
      context: ./implementation
      dockerfile: Dockerfile
    container_name: ddn-flower
    ports:
      - "5555:5555"
    environment:
      - REDIS_URL=redis://redis:6379/0
    networks:
      - ddn-network
    depends_on:
      - redis
    restart: unless-stopped
    command: celery -A tasks.celery_tasks flower --port=5555 --broker=redis://redis:6379/0

  # ============================================================================
  # WORKFLOW AUTOMATION
  # ============================================================================

  # n8n - Workflow automation (using SQLite for workflow storage)
  n8n:
    image: n8nio/n8n:latest
    container_name: ddn-n8n
    ports:
      - "5678:5678"
    environment:
      - N8N_BASIC_AUTH_ACTIVE=true
      - N8N_BASIC_AUTH_USER=admin
      - N8N_BASIC_AUTH_PASSWORD=password
      - WEBHOOK_URL=http://localhost:5678/
    volumes:
      - D:/rancher-storage/volumes/n8n-data:/home/node/.n8n
      - ./implementation/workflows:/workflows
    networks:
      - ddn-network
    restart: unless-stopped

  # ============================================================================
  # TASK WORKERS
  # ============================================================================

  # Celery Worker - Async task processing
  celery-worker:
    build:
      context: ./implementation
      dockerfile: Dockerfile
    container_name: ddn-celery-worker
    environment:
      - REDIS_URL=redis://redis:6379/0
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - MONGODB_URI=${MONGODB_URI}
      - PINECONE_API_KEY=${PINECONE_API_KEY}
      - LANGFUSE_ENABLED=true
      - LANGFUSE_HOST=http://langfuse-server:3000
      - LANGFUSE_PUBLIC_KEY=${LANGFUSE_PUBLIC_KEY}
      - LANGFUSE_SECRET_KEY=${LANGFUSE_SECRET_KEY}
    networks:
      - ddn-network
    depends_on:
      - redis
    restart: unless-stopped
    command: celery -A tasks.celery_tasks worker --loglevel=info --concurrency=4 --pool=solo

  # ============================================================================
  # CORE AI SERVICES
  # ============================================================================

  # LangGraph Classification Service
  langgraph-service:
    build:
      context: ./implementation
      dockerfile: Dockerfile
    container_name: ddn-langgraph
    ports:
      - "5000:5000"
    environment:
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - MONGODB_URI=${MONGODB_URI}
      - MONGODB_DB=ddn_tests
      - PINECONE_API_KEY=${PINECONE_API_KEY}
      - PINECONE_INDEX_NAME=test-failures
      - REDIS_URL=redis://redis:6379/0
      - LANGFUSE_ENABLED=true
      - LANGFUSE_HOST=http://langfuse-server:3000
      - LANGFUSE_PUBLIC_KEY=${LANGFUSE_PUBLIC_KEY}
      - LANGFUSE_SECRET_KEY=${LANGFUSE_SECRET_KEY}
    networks:
      - ddn-network
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped
    command: python langgraph_agent.py

  # ============================================================================
  # MCP SERVERS (Model Context Protocol)
  # ============================================================================

  # MongoDB MCP Server
  mcp-mongodb:
    build:
      context: ./mcp-configs
      dockerfile: Dockerfile
    container_name: ddn-mcp-mongodb
    ports:
      - "5001:5001"
    environment:
      - MONGODB_URI=${MONGODB_URI}
      - MONGODB_DB=ddn_tests
    networks:
      - ddn-network
    restart: unless-stopped
    command: python mcp_mongodb_server.py

  # GitHub MCP Server
  mcp-github:
    build:
      context: ./mcp-configs
      dockerfile: Dockerfile
    container_name: ddn-mcp-github
    ports:
      - "5002:5002"
    environment:
      - GITHUB_TOKEN=${GITHUB_TOKEN}
      - GITHUB_REPO=${GITHUB_REPO}
    networks:
      - ddn-network
    restart: unless-stopped
    command: python mcp_github_server.py

  # ============================================================================
  # API SERVICES
  # ============================================================================

  # Manual Trigger API
  manual-trigger-api:
    build:
      context: ./implementation
      dockerfile: Dockerfile
    container_name: ddn-manual-trigger
    ports:
      - "5004:5004"
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=ddn_ai_analysis
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - N8N_WEBHOOK_URL=http://n8n:5678/webhook/ddn-test-failure
    networks:
      - ddn-network
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    command: python manual_trigger_api.py

  # Dashboard Backend API
  dashboard-api:
    build:
      context: ./implementation
      dockerfile: Dockerfile
    container_name: ddn-dashboard-api
    ports:
      - "5006:5006"  # Dashboard API port
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=ddn_ai_analysis
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - MONGODB_URI=${MONGODB_URI}
      - MONGODB_DB=ddn_tests
      - MANUAL_TRIGGER_API=http://manual-trigger-api:5004
      - GITHUB_TOKEN=${GITHUB_TOKEN}
      - GITHUB_REPO=${GITHUB_REPO}
      - PINECONE_API_KEY=${PINECONE_API_KEY}
      - PINECONE_INDEX_NAME=${PINECONE_INDEX_NAME}
      - PINECONE_HOST=${PINECONE_HOST}
    networks:
      - ddn-network
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    command: python dashboard_api_full.py

  # ============================================================================
  # INTEGRATION SERVICES
  # ============================================================================

  # Jira Integration Service
  jira-service:
    build:
      context: ./implementation
      dockerfile: Dockerfile
    container_name: ddn-jira
    ports:
      - "5009:5009"
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=ddn_ai_analysis
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - JIRA_URL=${JIRA_URL}
      - JIRA_EMAIL=${JIRA_EMAIL}
      - JIRA_API_TOKEN=${JIRA_API_TOKEN}
      - JIRA_PROJECT_KEY=${JIRA_PROJECT_KEY}
      - JIRA_SERVICE_PORT=5009
    networks:
      - ddn-network
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    command: python jira_integration_service.py

  # Slack Integration Service
  slack-service:
    build:
      context: ./implementation
      dockerfile: Dockerfile
    container_name: ddn-slack
    ports:
      - "5012:5012"
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=ddn_ai_analysis
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - SLACK_BOT_TOKEN=${SLACK_BOT_TOKEN}
      - SLACK_SIGNING_SECRET=${SLACK_SIGNING_SECRET}
      - SLACK_DEFAULT_CHANNEL=${SLACK_DEFAULT_CHANNEL}
      - SLACK_SERVICE_PORT=5012
      - DASHBOARD_URL=http://localhost:3000
    networks:
      - ddn-network
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    command: python slack_integration_service.py

  # Self-Healing Service
  self-healing-service:
    build:
      context: ./implementation
      dockerfile: Dockerfile
    container_name: ddn-self-healing
    ports:
      - "5008:5008"
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=ddn_ai_analysis
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - JENKINS_URL=${JENKINS_URL}
      - JENKINS_USER=${JENKINS_USER}
      - JENKINS_TOKEN=${JENKINS_TOKEN}
      - GITHUB_TOKEN=${GITHUB_TOKEN}
      - GITHUB_REPO=${GITHUB_REPO}
      - SELF_HEALING_SAFE_MODE=true
      - MIN_SUCCESS_RATE=0.8
      - MIN_PATTERN_OCCURRENCES=3
    networks:
      - ddn-network
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    command: python self_healing_service.py

  # Service Manager API
  service-manager:
    build:
      context: ./implementation
      dockerfile: Dockerfile
    container_name: ddn-service-manager
    ports:
      - "5007:5007"
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=ddn_ai_analysis
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - MONGODB_URI=${MONGODB_URI}
      - MONGODB_DB=ddn_tests
      - SERVICE_MANAGER_PORT=5007
    networks:
      - ddn-network
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    command: python service_manager_api.py

  # Aging Service
  aging-service:
    build:
      context: ./implementation
      dockerfile: Dockerfile
    container_name: ddn-aging-service
    ports:
      - "5010:5010"
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=ddn_ai_analysis
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - MONGODB_URI=${MONGODB_URI}
      - MONGODB_DB=ddn_tests
      - AGING_SERVICE_PORT=5010
      - CHECK_INTERVAL_HOURS=24
    networks:
      - ddn-network
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    command: python aging_service.py

  # Knowledge Management API
  knowledge-management-api:
    build:
      context: ./implementation
      dockerfile: Dockerfile
    container_name: ddn-knowledge-mgmt
    ports:
      - "5015:5015"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - PINECONE_API_KEY=${PINECONE_API_KEY}
      - PINECONE_INDEX_NAME=test-failures
      - KNOWLEDGE_API_PORT=5015
      - MONGODB_URI=${MONGODB_URI}
      - MONGODB_DB=ddn_tests
    networks:
      - ddn-network
    restart: unless-stopped
    command: python knowledge_management_api.py

  # Re-Ranking Service
  reranking-service:
    build:
      context: ./implementation
      dockerfile: Dockerfile
    container_name: ddn-reranking
    ports:
      - "5011:5011"
    environment:
      - RERANKING_SERVICE_PORT=5011
      - RERANKING_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2
      - MONGODB_URI=${MONGODB_URI}
      - MONGODB_DB=ddn_tests
    networks:
      - ddn-network
    restart: unless-stopped
    command: python reranking_service.py

  # ============================================================================
  # FRONTEND
  # ============================================================================

  # Dashboard Frontend (React)
  dashboard-ui:
    build:
      context: ./implementation/dashboard-ui
      dockerfile: Dockerfile
      target: production  # Use production stage for built static files
    container_name: ddn-dashboard-ui
    ports:
      - "5173:5173"
    environment:
      - VITE_API_URL=http://dashboard-api:5006
      - VITE_JIRA_API_URL=http://jira-service:5009
      - VITE_SLACK_API_URL=http://slack-service:5012
      - VITE_KNOWLEDGE_API_URL=http://knowledge-management-api:5015
      - VITE_SERVICE_MANAGER_URL=http://service-manager:5007
    networks:
      - ddn-network
    depends_on:
      - dashboard-api
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "wget -q --spider http://localhost:5173 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Dashboard Frontend (Development Mode) - Use with: docker compose up dashboard-ui-dev
  dashboard-ui-dev:
    build:
      context: ./implementation/dashboard-ui
      dockerfile: Dockerfile
      target: development  # Use development stage for hot reload
    container_name: ddn-dashboard-ui-dev
    ports:
      - "5173:5173"
    environment:
      - VITE_API_URL=http://dashboard-api:5006
      - VITE_JIRA_API_URL=http://jira-service:5009
      - VITE_SLACK_API_URL=http://slack-service:5012
      - VITE_KNOWLEDGE_API_URL=http://knowledge-management-api:5015
      - VITE_SERVICE_MANAGER_URL=http://service-manager:5007
    volumes:
      - ./implementation/dashboard-ui/src:/app/src:ro  # Mount source for hot reload
    networks:
      - ddn-network
    depends_on:
      - dashboard-api
    restart: unless-stopped
    profiles:
      - dev  # Only start with: docker compose --profile dev up

  # ============================================================================
  # CI/CD
  # ============================================================================

  # Jenkins CI Server
  jenkins:
    image: jenkins/jenkins:lts
    container_name: ddn-jenkins
    ports:
      - "8081:8081"
      - "50000:50000"
    environment:
      - JENKINS_OPTS=--httpPort=8081
    volumes:
      - D:/rancher-storage/volumes/jenkins-data:/var/jenkins_home
    networks:
      - ddn-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8081/login || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s

# ============================================================================
# NETWORKS
# ============================================================================
networks:
  ddn-network:
    driver: bridge

# ============================================================================
# VOLUMES (Using D: drive for Rancher Desktop)
# ============================================================================
# All volumes now use bind mounts to D:/rancher-storage/volumes/
# No named volumes needed - data persists on D: drive
